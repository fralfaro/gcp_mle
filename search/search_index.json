{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u2601\ufe0f Bienvenido a Machine Learning con GCP","text":""},{"location":"#contenidos-del-curso","title":"\ud83d\udcda Contenidos del Curso","text":"<p>IAM y Seguridad</p><p>Aprende a gestionar identidades, roles, permisos y cuentas de servicio en GCP para proteger tus proyectos de ML.</p> <p>Almacenamiento de Datos</p><p>Conoce c\u00f3mo usar Cloud Storage y BigQuery para almacenar datasets estructurados y no estructurados a escala.</p> <p>Procesamiento de Datos</p><p>Usa Dataflow, Dataproc y BigQuery para transformar grandes vol\u00famenes de datos de manera eficiente y escalable.</p> <p>Automatizaci\u00f3n y Pipelines</p><p>Dise\u00f1a y orquesta flujos de trabajo ML con Vertex Pipelines, Workflows y Composer.</p> <p>Modelos y Entrenamiento</p><p>Entrena modelos en Vertex AI, explora AutoML y despliega soluciones de ML en producci\u00f3n.</p> <p>Extras</p><p>M\u00e1s sobre otros servicios de GCP, como Data Studio, Looker y herramientas de visualizaci\u00f3n.</p>"},{"location":"unit1/","title":"\ud83d\udcd8 Unidad 1: IAM y Seguridad","text":"<p>Esta unidad te introduce a la gesti\u00f3n de identidades y accesos en Google Cloud, un aspecto fundamental para proteger tus proyectos de Machine Learning.</p>"},{"location":"unit1/#capitulos","title":"\ud83d\udcc4 Cap\u00edtulos","text":"Archivo T\u00edtulo Descripci\u00f3n breve <code>iam/intro.md</code> \ud83d\udd10 Introducci\u00f3n a IAM Qu\u00e9 es IAM, por qu\u00e9 es importante y c\u00f3mo se aplica en GCP. <code>iam/roles.md</code> \ud83c\udfad Roles y pol\u00edticas Tipos de roles (b\u00e1sicos, predefinidos, personalizados) y c\u00f3mo asignarlos. <code>iam/service-accounts.md</code> \ud83e\uddfe Cuentas de servicio Qu\u00e9 son, c\u00f3mo crearlas y c\u00f3mo se usan para automatizar procesos. <code>iam/best-practices.md</code> \u2705 Buenas pr\u00e1cticas de acceso Consejos y patrones recomendados para aplicar el principio de menor privilegio."},{"location":"unit1/intro/","title":"Introducci\u00f3n a IAM","text":""},{"location":"unit1/intro/#introduccion","title":"Introducci\u00f3n","text":"<p>El sistema Identity and Access Management (IAM) de Google Cloud permite definir qui\u00e9n puede hacer qu\u00e9 sobre qu\u00e9 recurso. En proyectos de Machine Learning, esto es esencial para proteger datos, controlar accesos a modelos y automatizar procesos de manera segura.</p> <p>En este cap\u00edtulo, aprender\u00e1s los componentes principales de IAM, c\u00f3mo aplicarlos y por qu\u00e9 es fundamental entender esta arquitectura para cualquier proyecto en la nube.</p>"},{"location":"unit1/intro/#por-que-es-importante-entender-iam","title":"\u00bfPor qu\u00e9 es importante entender IAM?","text":"<p>Comprender c\u00f3mo funciona IAM te permitir\u00e1:</p> <ul> <li>Prevenir accesos no autorizados a tus datos o modelos.</li> <li>Automatizar flujos de trabajo de manera segura con cuentas de servicio.</li> <li>Implementar el principio de menor privilegio y reducir riesgos.</li> <li>Diagnosticar errores de permisos y optimizar configuraciones de seguridad.</li> </ul>"},{"location":"unit1/intro/#componentes-principales-de-iam","title":"Componentes principales de IAM","text":"<p>Google Cloud aplica IAM en una jerarqu\u00eda: organizaci\u00f3n \u2192 carpeta \u2192 proyecto \u2192 recurso.</p> <p>A continuaci\u00f3n, los elementos clave del sistema:</p>"},{"location":"unit1/intro/#1-principals-identidades","title":"1. Principals (Identidades)","text":"<ul> <li>Representan a quien accede a los recursos.</li> <li>Pueden ser: usuarios (<code>user:</code>), grupos (<code>group:</code>), cuentas de servicio (<code>serviceAccount:</code>) o dominios.</li> </ul>"},{"location":"unit1/intro/#2-roles","title":"2. Roles","text":"<ul> <li>Definen un conjunto de permisos.</li> <li>Tipos:</li> <li>B\u00e1sicos: Owner, Editor, Viewer.</li> <li>Predefinidos: roles espec\u00edficos por servicio (ej. <code>roles/storage.objectViewer</code>).</li> <li>Personalizados: creados por el usuario.</li> </ul>"},{"location":"unit1/intro/#3-permisos","title":"3. Permisos","text":"<ul> <li>Son acciones sobre recursos, como:</li> <li><code>storage.buckets.get</code></li> <li><code>bigquery.datasets.create</code></li> </ul>"},{"location":"unit1/intro/#4-politicas","title":"4. Pol\u00edticas","text":"<ul> <li>Asocian uno o m\u00e1s roles a uno o m\u00e1s principals.</li> <li>Se aplican a un recurso espec\u00edfico (proyecto, bucket, dataset, etc.).</li> </ul>"},{"location":"unit1/intro/#diagrama-logico-de-iam-en-gcp","title":"Diagrama l\u00f3gico de IAM en GCP","text":"<pre><code>Organizaci\u00f3n\n \u2514\u2500\u2500 Carpeta (opcional)\n      \u2514\u2500\u2500 Proyecto\n           \u2514\u2500\u2500 Recurso (bucket, modelo, tabla...)\n</code></pre> <p>Las pol\u00edticas se heredan hacia abajo. Si das un rol a nivel de proyecto, todos los recursos dentro de ese proyecto lo heredar\u00e1n.</p>"},{"location":"unit1/intro/#ejemplo-practico","title":"Ejemplo pr\u00e1ctico","text":"<p>Otorgar permisos de lectura a un bucket de Storage para un usuario:</p> <pre><code>gcloud projects add-iam-policy-binding mi-proyecto-id \\\n  --member=\"user:persona@ejemplo.com\" \\\n  --role=\"roles/storage.objectViewer\"\n</code></pre> <p>Este comando: - A\u00f1ade una pol\u00edtica de IAM al proyecto. - Aplica el rol de visualizador de objetos de Storage. - Asocia ese rol al usuario especificado.</p>"},{"location":"unit1/intro/#iam-en-proyectos-de-ml","title":"IAM en proyectos de ML","text":"<p>IAM se usa en cada etapa del ciclo de vida de Machine Learning:</p> <ul> <li>\ud83d\udd12 Acceso a datasets en Storage o BigQuery.</li> <li>\ud83e\udde0 Entrenamiento de modelos con Vertex AI (y cuentas de servicio dedicadas).</li> <li>\ud83d\ude80 Despliegue de modelos y control de endpoints.</li> <li>\ud83e\udd16 Automatizaci\u00f3n con Workflows, Cloud Functions, y pipelines de Vertex AI.</li> </ul>"},{"location":"unit1/intro/#recomendaciones-clave","title":"Recomendaciones clave","text":"<ul> <li>\u2705 Aplica el principio de menor privilegio.</li> <li>\ud83d\udd10 Usa cuentas de servicio separadas para pipelines y tareas autom\u00e1ticas.</li> <li>\ud83e\udde9 Prefiere roles predefinidos antes de crear personalizados.</li> <li>\ud83d\udcca Supervisa accesos con Cloud Audit Logs.</li> </ul>"},{"location":"unit1/intro/#referencias-utiles","title":"Referencias \u00fatiles","text":"<ul> <li>Documentaci\u00f3n oficial de IAM</li> <li>Comando <code>gcloud</code> para IAM</li> <li>IAM para Vertex AI</li> </ul>"},{"location":"unit1/intro/#conclusion","title":"Conclusi\u00f3n","text":"<p>IAM es el primer paso para construir soluciones seguras y escalables en GCP. Con una buena gesti\u00f3n de accesos, no solo proteges tus datos y modelos, sino que tambi\u00e9n simplificas la automatizaci\u00f3n y el trabajo colaborativo.</p> <p>En el siguiente cap\u00edtulo exploraremos c\u00f3mo funcionan los roles y pol\u00edticas para asignar permisos de forma granular.</p>"},{"location":"unit1/roles/","title":"Roles y Pol\u00edticas","text":""},{"location":"unit1/roles/#introduccion","title":"Introducci\u00f3n","text":"<p>En IAM, los roles definen el conjunto de acciones (permisos) que una identidad puede realizar sobre un recurso. Las pol\u00edticas vinculan esos roles a identidades espec\u00edficas dentro de un alcance determinado, como un proyecto o bucket.</p> <p>Comprender esta relaci\u00f3n es clave para implementar accesos seguros, eficientes y escalables.</p>"},{"location":"unit1/roles/#por-que-es-importante-entender-los-roles","title":"\u00bfPor qu\u00e9 es importante entender los roles?","text":"<p>Los roles son la forma en que GCP controla el acceso. Usar el rol adecuado:</p> <ul> <li>Minimiza riesgos de seguridad.</li> <li>Mejora la gobernanza.</li> <li>Permite delegar tareas sin exponer servicios cr\u00edticos.</li> </ul>"},{"location":"unit1/roles/#tipos-de-roles-en-iam","title":"Tipos de roles en IAM","text":"<p>Google Cloud define tres tipos de roles:</p>"},{"location":"unit1/roles/#1-roles-basicos","title":"1. Roles B\u00e1sicos","text":"Rol Permisos Owner Control total sobre todos los recursos (incluye IAM). Editor Modifica recursos pero no gestiona IAM. Viewer Solo lectura sobre recursos. <p>\u2757 No recomendados para producci\u00f3n, ya que son muy amplios.</p>"},{"location":"unit1/roles/#2-roles-predefinidos","title":"2. Roles Predefinidos","text":"<ul> <li>Dise\u00f1ados para servicios espec\u00edficos.</li> <li>Ejemplos:</li> <li><code>roles/storage.objectViewer</code>: lectura de objetos en Cloud Storage.</li> <li><code>roles/bigquery.dataEditor</code>: edici\u00f3n de tablas en BigQuery.</li> <li><code>roles/ml.developer</code>: acceso a entrenamiento y despliegue en Vertex AI.</li> </ul> <p>\u2705 Recomendados para controlar el acceso de manera precisa y segura.</p>"},{"location":"unit1/roles/#3-roles-personalizados","title":"3. Roles Personalizados","text":"<ul> <li>Creados por el usuario.</li> <li>Permiten definir exactamente qu\u00e9 permisos incluir.</li> <li>\u00datiles cuando ning\u00fan rol predefinido se ajusta a las necesidades.</li> </ul> <pre><code>gcloud iam roles create customViewer \\\n  --project=mi-proyecto-id \\\n  --title=\"Custom Viewer\" \\\n  --permissions=\"storage.buckets.get,storage.objects.list\" \\\n  --stage=GA\n</code></pre>"},{"location":"unit1/roles/#politicas-iam","title":"Pol\u00edticas IAM","text":"<p>Una pol\u00edtica de IAM define qui\u00e9n tiene qu\u00e9 rol sobre qu\u00e9 recurso.</p>"},{"location":"unit1/roles/#estructura-simplificada","title":"Estructura simplificada:","text":"<pre><code>{\n  \"bindings\": [\n    {\n      \"role\": \"roles/storage.objectViewer\",\n      \"members\": [\n        \"user:usuario@ejemplo.com\"\n      ]\n    }\n  ]\n}\n</code></pre> <ul> <li><code>bindings</code>: lista de asignaciones.</li> <li><code>role</code>: el rol otorgado.</li> <li><code>members</code>: las identidades que lo reciben.</li> </ul>"},{"location":"unit1/roles/#ejemplo-practico-acceso-granular-a-bigquery","title":"Ejemplo pr\u00e1ctico: acceso granular a BigQuery","text":"<pre><code>gcloud projects add-iam-policy-binding mi-proyecto-id \\\n  --member=\"serviceAccount:mi-pipeline@mi-proyecto.iam.gserviceaccount.com\" \\\n  --role=\"roles/bigquery.dataViewer\"\n</code></pre> <p>Este comando permite que una cuenta de servicio acceda a datos de BigQuery, sin permitirle editar o borrar.</p>"},{"location":"unit1/roles/#buenas-practicas","title":"Buenas pr\u00e1cticas","text":"<ul> <li>\ud83c\udfaf Usa roles predefinidos siempre que sea posible.</li> <li>\ud83d\udd10 Evita <code>Owner</code> y <code>Editor</code> en producci\u00f3n.</li> <li>\ud83e\uddea Usa cuentas de servicio separadas por flujo de trabajo.</li> <li>\ud83e\udde9 Usa etiquetas o nombres descriptivos para los roles personalizados.</li> <li>\ud83e\uddfe Documenta las pol\u00edticas aplicadas por recurso y prop\u00f3sito.</li> </ul>"},{"location":"unit1/roles/#diagrama-de-relacion","title":"Diagrama de relaci\u00f3n","text":"<pre><code>[Principal]\n   |\n   v\n[Rol asignado] -----&gt; [Permisos]\n   |\n   v\n[Recurso (Proyecto, Bucket, Modelo...)]\n</code></pre>"},{"location":"unit1/roles/#referencias-utiles","title":"Referencias \u00fatiles","text":"<ul> <li>Tipos de roles en IAM</li> <li>Crear roles personalizados</li> <li>IAM Policy JSON</li> </ul>"},{"location":"unit1/roles/#conclusion","title":"Conclusi\u00f3n","text":"<p>Conocer los distintos tipos de roles te permitir\u00e1 aplicar pol\u00edticas de acceso m\u00e1s efectivas. Usar roles predefinidos y personalizar solo cuando sea necesario ayuda a mantener tu infraestructura segura y manejable.</p> <p>En el siguiente cap\u00edtulo aprender\u00e1s a trabajar con cuentas de servicio, esenciales para tareas automatizadas y pipelines de ML.</p>"},{"location":"unit2/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit2/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit2/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit2/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit2/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit2/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"},{"location":"unit3/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit3/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit3/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit3/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit3/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit3/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"},{"location":"unit4/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit4/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit4/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit4/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit4/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit4/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"},{"location":"unit5/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit5/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit5/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit5/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit5/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit5/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"},{"location":"unit6/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit6/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit6/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit6/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit6/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit6/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"}]}