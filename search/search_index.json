{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u2601\ufe0f Bienvenido a Machine Learning con GCP","text":""},{"location":"#contenidos-del-curso","title":"\ud83d\udcda Contenidos del Curso","text":"<p>IAM y Seguridad</p><p>Aprende a gestionar identidades, roles, permisos y cuentas de servicio en GCP para proteger tus proyectos de ML.</p> <p>Almacenamiento de Datos</p><p>Conoce c\u00f3mo usar Cloud Storage y BigQuery para almacenar datasets estructurados y no estructurados a escala.</p> <p>Procesamiento de Datos</p><p>Usa Dataflow, Dataproc y BigQuery para transformar grandes vol\u00famenes de datos de manera eficiente y escalable.</p> <p>Automatizaci\u00f3n y Pipelines</p><p>Dise\u00f1a y orquesta flujos de trabajo ML con Vertex Pipelines, Workflows y Composer.</p> <p>Modelos y Entrenamiento</p><p>Entrena modelos en Vertex AI, explora AutoML y despliega soluciones de ML en producci\u00f3n.</p> <p>Extras</p><p>M\u00e1s sobre otros servicios de GCP, como Data Studio, Looker y herramientas de visualizaci\u00f3n.</p>"},{"location":"unit1/","title":"\ud83d\udcd8 Unidad 1: IAM y Seguridad","text":"<p>Esta unidad te introduce a la gesti\u00f3n de identidades y accesos en Google Cloud, un aspecto fundamental para proteger tus proyectos de Machine Learning.</p>"},{"location":"unit1/#capitulos","title":"\ud83d\udcc4 Cap\u00edtulos","text":"Archivo T\u00edtulo Descripci\u00f3n breve <code>iam/intro.md</code> \ud83d\udd10 Introducci\u00f3n a IAM Qu\u00e9 es IAM, por qu\u00e9 es importante y c\u00f3mo se aplica en GCP. <code>iam/roles.md</code> \ud83c\udfad Roles y pol\u00edticas Tipos de roles (b\u00e1sicos, predefinidos, personalizados) y c\u00f3mo asignarlos. <code>iam/service-accounts.md</code> \ud83e\uddfe Cuentas de servicio Qu\u00e9 son, c\u00f3mo crearlas y c\u00f3mo se usan para automatizar procesos. <code>iam/best-practices.md</code> \u2705 Buenas pr\u00e1cticas de acceso Consejos y patrones recomendados para aplicar el principio de menor privilegio."},{"location":"unit2/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit2/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit2/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit2/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit2/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit2/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"},{"location":"unit3/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit3/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit3/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit3/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit3/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit3/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"},{"location":"unit4/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit4/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit4/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit4/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit4/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit4/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"},{"location":"unit5/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit5/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit5/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit5/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit5/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit5/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"},{"location":"unit6/","title":"\ud83d\udd25 Fundamentos de PySpark","text":"<p>La Unidad 1 te introduce al mundo del procesamiento distribuido con Apache Spark usando Python. Aqu\u00ed aprender\u00e1s a manejar grandes vol\u00famenes de datos de manera eficiente, utilizando transformaciones, acciones y consultas SQL sobre estructuras distribuidas. Esta unidad es clave para trabajar con Big Data de forma escalable y profesional.</p>"},{"location":"unit6/#objetivos-de-la-unidad","title":"\ud83c\udfaf Objetivos de la unidad","text":"<ul> <li>Comprender el modelo de ejecuci\u00f3n distribuido de Spark.</li> <li>Crear y transformar estructuras de datos distribuidas (RDD y DataFrame).</li> <li>Ejecutar operaciones con <code>transformations</code> y <code>actions</code>.</li> <li>Consultar datos usando Spark SQL.</li> <li>Comprender el flujo de trabajo de un job de Spark.</li> <li>Integrar Spark en entornos locales o en la nube.</li> </ul>"},{"location":"unit6/#contenidos","title":"\ud83d\udcda Contenidos","text":"Tema Descripci\u00f3n breve \u2699\ufe0f Introducci\u00f3n a Spark y PySpark Qu\u00e9 es Spark, c\u00f3mo funciona y c\u00f3mo lo usamos con Python. \ud83d\udce6 RDD y DataFrames Tipos de estructuras distribuidas, diferencias y casos de uso. \ud83d\udd01 Transformaciones y Acciones C\u00f3mo manipular y procesar los datos de forma eficiente. \ud83e\udde0 Lazy Evaluation Ejecuci\u00f3n diferida y optimizaci\u00f3n autom\u00e1tica del plan de ejecuci\u00f3n. \ud83d\udd0d Spark SQL Consultas tipo SQL sobre grandes conjuntos de datos. \ud83e\uddea Spark Streaming (b\u00e1sico) Introducci\u00f3n al procesamiento de datos en tiempo real."},{"location":"unit6/#recomendacion","title":"\ud83e\udde0 Recomendaci\u00f3n","text":"<p>Te sugerimos comenzar por la introducci\u00f3n conceptual y luego avanzar paso a paso por las transformaciones, SQL y finalmente streaming. Aseg\u00farate de ejecutar los ejemplos t\u00fa mismo para entender c\u00f3mo Spark distribuye las operaciones.</p>"},{"location":"unit6/#prerrequisitos","title":"\ud83d\udcda Prerrequisitos","text":"<ul> <li>Conocimientos intermedios de Python</li> <li>Familiaridad con estructuras tipo <code>DataFrame</code></li> <li>Entorno configurado para ejecutar PySpark</li> </ul>"},{"location":"unit6/#que-lograras-al-finalizar-esta-unidad","title":"\u2705 \u00bfQu\u00e9 lograr\u00e1s al finalizar esta unidad?","text":"<ul> <li>Procesar grandes vol\u00famenes de datos con PySpark.</li> <li>Utilizar transformaciones y acciones de forma eficiente.</li> <li>Consultar datos con Spark SQL.</li> <li>Comprender c\u00f3mo funciona un motor de ejecuci\u00f3n distribuido.</li> </ul>"}]}